{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd85b170-be9b-4604-bc94-03d141cf3b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muhammadali uchun ID: 2\n",
      "Rasmlar dataset\\2 ichiga saqlanadi.\n",
      "Muhammadali uchun 50 ta rasm saqlandi. ID: 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from facenet_pytorch import MTCNN\n",
    "\n",
    "# Qurilmani aniqlash\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Model yuklash\n",
    "mtcnn = MTCNN(keep_all=True, device=device)\n",
    "\n",
    "# Dataset papkasini yaratish\n",
    "DATASET_PATH = \"dataset\"\n",
    "if not os.path.exists(DATASET_PATH):\n",
    "    os.makedirs(DATASET_PATH)\n",
    "\n",
    "# Yangi ID yaratish funksiyasi\n",
    "def get_new_id():\n",
    "    existing_ids = [int(folder) for folder in os.listdir(DATASET_PATH) if folder.isdigit()]\n",
    "    return max(existing_ids) + 1 if existing_ids else 1\n",
    "\n",
    "# Kamera ochish\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Foydalanuvchi nomini kiritish\n",
    "person_name = input(\"Foydalanuvchi ismini kiriting: \").strip()\n",
    "person_id = get_new_id()  # Yangi ID yaratish\n",
    "save_path = os.path.join(DATASET_PATH, str(person_id))\n",
    "\n",
    "# Rasm saqlash uchun papka yaratish\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "print(f\"{person_name} uchun ID: {person_id}\")\n",
    "print(f\"Rasmlar {save_path} ichiga saqlanadi.\")\n",
    "\n",
    "frame_count = 0\n",
    "max_frames = 50  # Har bir shaxs uchun 50 ta rasm\n",
    "\n",
    "while frame_count < max_frames:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    boxes, _ = mtcnn.detect(rgb_frame)\n",
    "\n",
    "    if boxes is not None:\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = [int(b) for b in box]\n",
    "            face = rgb_frame[y1:y2, x1:x2]\n",
    "\n",
    "            if face.size == 0:\n",
    "                continue\n",
    "\n",
    "            frame_count += 1\n",
    "            file_name = f\"{frame_count}.jpg\"\n",
    "            file_path = os.path.join(save_path, file_name)\n",
    "\n",
    "            # Rasmni saqlash\n",
    "            cv2.imwrite(file_path, cv2.cvtColor(face, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "            # Yuzni belgilash\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Saving {frame_count}/{max_frames}\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Face Capture\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "print(f\"{person_name} uchun 50 ta rasm saqlandi. ID: {person_id}\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a57e2c03-e314-461e-aa32-704b08fc1921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Yuz topilmadi: dataset\\1\\1.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\10.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\11.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\12.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\13.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\14.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\17.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\18.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\19.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\2.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\20.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\21.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\22.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\24.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\25.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\26.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\27.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\28.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\29.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\3.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\30.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\31.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\32.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\33.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\34.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\35.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\36.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\37.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\38.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\39.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\4.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\40.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\41.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\42.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\43.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\44.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\45.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\46.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\48.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\49.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\5.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\6.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\7.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\8.jpg\n",
      "[!] Yuz topilmadi: dataset\\1\\9.jpg\n",
      "[!] Yuz topilmadi: dataset\\2\\1.jpg\n",
      "[!] Yuz topilmadi: dataset\\2\\2.jpg\n",
      "[!] Yuz topilmadi: dataset\\2\\3.jpg\n",
      "2 ta foydalanuvchi yuklandi.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from PIL import Image\n",
    "\n",
    "# Qurilmani aniqlash\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Model yuklash\n",
    "mtcnn = MTCNN(keep_all=False, device=device)  # Faqat bitta yuz kerak bo‘lsa\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "\n",
    "# Transform funksiyasi\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((160, 160)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Embedding olish funksiyasi\n",
    "def get_embedding(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"[X] Rasm ochilmadi: {image_path}\")\n",
    "        return None\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_pil = Image.fromarray(img).convert(\"RGB\")\n",
    "\n",
    "    try:\n",
    "        boxes, _ = mtcnn.detect(img_pil)\n",
    "        if boxes is None or len(boxes) == 0:\n",
    "            print(f\"[!] Yuz topilmadi: {image_path}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"[X] MTCNN.detect xatolik ({image_path}): {e}\")\n",
    "        return None\n",
    "\n",
    "    x1, y1, x2, y2 = [int(v) for v in boxes[0]]\n",
    "    h, w, _ = img.shape\n",
    "    x1, y1, x2, y2 = [max(0, min(p, limit)) for p, limit in zip([x1, y1, x2, y2], [w, h, w, h])]\n",
    "\n",
    "    face = img[y1:y2, x1:x2]\n",
    "    if face.size == 0:\n",
    "        print(f\"[!] Bo‘sh yuz maydoni: {image_path}\")\n",
    "        return None\n",
    "\n",
    "    face_tensor = transform(face).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        embedding = resnet(face_tensor).cpu().numpy()[0]\n",
    "\n",
    "    return embedding\n",
    "\n",
    "# Datasetdan yuzlarni embedding qilish\n",
    "DATASET_PATH = \"dataset\"\n",
    "known_faces = {}\n",
    "\n",
    "for person_id in os.listdir(DATASET_PATH):\n",
    "    person_path = os.path.join(DATASET_PATH, person_id)\n",
    "    if os.path.isdir(person_path):\n",
    "        images = [os.path.join(person_path, img) for img in os.listdir(person_path) if img.endswith(\".jpg\")]\n",
    "        embeddings = [get_embedding(img) for img in images]\n",
    "        embeddings = [e for e in embeddings if e is not None]\n",
    "\n",
    "        if embeddings:\n",
    "            known_faces[person_id] = np.mean(embeddings, axis=0)\n",
    "\n",
    "print(f\"{len(known_faces)} ta foydalanuvchi yuklandi.\")\n",
    "\n",
    "# Jonli kameradan yuzni tanish\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img_pil = Image.fromarray(rgb_frame)\n",
    "\n",
    "    boxes, _ = mtcnn.detect(img_pil)\n",
    "\n",
    "    if boxes is not None:\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = [int(v) for v in box]\n",
    "            h, w, _ = frame.shape\n",
    "            x1, y1, x2, y2 = [max(0, min(p, limit)) for p, limit in zip([x1, y1, x2, y2], [w, h, w, h])]\n",
    "            face = rgb_frame[y1:y2, x1:x2]\n",
    "\n",
    "            if face.size == 0:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                face_tensor = transform(face).unsqueeze(0).to(device)\n",
    "                embedding = resnet(face_tensor).detach().cpu().numpy()\n",
    "\n",
    "                best_match = \"Unknown\"\n",
    "                best_similarity = 0\n",
    "\n",
    "                for person_id, known_embedding in known_faces.items():\n",
    "                    similarity = np.dot(embedding, known_embedding.T) / (np.linalg.norm(embedding) * np.linalg.norm(known_embedding))\n",
    "                    if similarity > best_similarity:\n",
    "                        best_similarity = similarity\n",
    "                        best_match = f\"ID: {person_id}\"\n",
    "\n",
    "                if best_similarity > 0.8:\n",
    "                    text, color = best_match, (0, 255, 0)\n",
    "                else:\n",
    "                    text, color = \"Unknown\", (0, 0, 255)\n",
    "\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                cv2.putText(frame, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"Error:\", e)\n",
    "\n",
    "    cv2.imshow(\"Face Recognition\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95ead905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.6.0+cpu\n",
      "CUDA available: False\n",
      "OpenCV: 4.10.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"OpenCV:\", cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d117066",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
